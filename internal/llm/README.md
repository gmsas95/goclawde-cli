# LLM Package

Language model provider abstractions:

- OpenAI-compatible API client
- Kimi K2.5 native support
- Streaming response handling
- Rate limiting and retries
