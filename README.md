# Jimmy.ai ğŸ¤–

> Your personal AI assistant that runs entirely on your own machine.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Go Version](https://img.shields.io/badge/go-%3E%3D1.23-blue)](https://golang.org)

**Jimmy.ai** is an open-source, self-hosted AI assistant inspired by [OpenClaw](https://github.com/openclaw/openclaw). It keeps your data local while providing powerful AI capabilities through your choice of LLM providers.

## ğŸŒŸ Features

- ğŸ”’ **Privacy First** - Your data never leaves your machine
- ğŸ’» **Self-Hosted** - Single binary, zero external dependencies
- ğŸ§© **Skills System** - Extensible plugin architecture (GitHub, Weather, Notes)
- ğŸ’¬ **Multi-Channel** - Web UI, CLI, Telegram bot (Discord/Slack coming)
- ğŸ”„ **Persistent Memory** - Remembers conversations and facts
- ğŸ”§ **Tool Use** - File operations, web search, shell commands
- ğŸ¤– **Background Tasks** - Spawn subagents for complex work
- â° **Cron Jobs** - Scheduled automation (coming in v0.4)
- ğŸ§  **Vector Memory** - RAG with semantic search (coming in v0.5)
- âš¡ **Lightning Fast** - Written in Go for maximum performance

## ğŸš€ Quick Start

### Option 1: Binary Download (Easiest)

```bash
# Download latest release
curl -L https://github.com/YOUR_USERNAME/jimmy.ai/releases/latest/download/jimmy-linux-amd64 -o jimmy
chmod +x jimmy

# Configure
export JIMMY_LLM_PROVIDERS_KIMI_API_KEY="your-kimi-api-key"

# Run
./jimmy

# Open http://localhost:8080
```

### Option 2: Build from Source

```bash
# Prerequisites: Go 1.23+, Node.js 20+
git clone https://github.com/YOUR_USERNAME/jimmy.ai.git
cd jimmy.ai

# Build
make build

# Run
./bin/jimmy
```

### Option 3: Docker

```bash
docker run -d \
  -p 8080:8080 \
  -v jimmy-data:/app/data \
  -e JIMMY_LLM_PROVIDERS_KIMI_API_KEY="sk-..." \
  ghcr.io/YOUR_USERNAME/jimmy.ai:latest
```

## ğŸ’» CLI Usage

Jimmy.ai works great as a command-line tool:

```bash
# One-shot query
./jimmy -m "Explain quantum computing in simple terms"

# Interactive mode
./jimmy --cli

# Pipe data
cat error.log | ./jimmy -m "What errors do you see?"
```

## ğŸ¤– Telegram Bot

Chat with Jimmy.ai directly on Telegram:

1. Get a bot token from [@BotFather](https://t.me/botfather)
2. Configure in `config.yaml`:
```yaml
channels:
  telegram:
    enabled: true
    bot_token: "${TELEGRAM_BOT_TOKEN}"
```
3. Start Jimmy.ai and send `/start` to your bot

**Commands:**
- `/start` - Welcome message
- `/help` - List available commands
- `/new` - Start a new conversation
- `/status` - Check bot status

## ğŸ§© Skills System

Jimmy.ai includes a powerful skills system for extending capabilities:

| Skill | Description | Example |
|-------|-------------|---------|
| `github` | GitHub operations | "Search for Go web frameworks" |
| `weather` | Weather forecasts | "What's the weather in Tokyo?" |
| `notes` | Note management | "Take a note: call mom tomorrow" |

**Configuration:**
```yaml
skills:
  enabled:
    - github
    - weather
    - notes
  
  github:
    token: "${GITHUB_TOKEN}"
  
  weather:
    api_key: "${WEATHER_API_KEY}"
```

See [FEATURES_v0.3.md](FEATURES_v0.3.md) for full documentation.

## ğŸ“ Configuration

Create `~/.local/share/jimmy/jimmy.yaml`:

```yaml
server:
  address: 0.0.0.0
  port: 8080

llm:
  default_provider: kimi
  providers:
    kimi:
      api_key: "your-kimi-api-key"
      model: "kimi-k2.5"
      base_url: "https://api.moonshot.cn/v1"
    openrouter:
      api_key: "your-openrouter-key"
      model: "anthropic/claude-3.5-sonnet"
      base_url: "https://openrouter.ai/api/v1"

# Built-in tools (system-level)
tools:
  enabled:
    - read_file
    - write_file
    - list_dir
    - exec_command
    - web_search

# Skills (high-level integrations)
skills:
  enabled:
    - github
    - weather
    - notes
  github:
    token: "${GITHUB_TOKEN}"
  weather:
    api_key: "${WEATHER_API_KEY}"

# Communication channels
channels:
  telegram:
    enabled: true
    bot_token: "${TELEGRAM_BOT_TOKEN}"
```

Or use environment variables:
```bash
export JIMMY_LLM_PROVIDERS_KIMI_API_KEY="sk-..."
export JIMMY_SKILLS_GITHUB_TOKEN="ghp_..."
export JIMMY_CHANNELS_TELEGRAM_BOT_TOKEN="..."
export JIMMY_SERVER_PORT=8080
```

## ğŸ—ï¸ Architecture

```
Jimmy.ai (~50MB single binary)
â”œâ”€â”€ Embedded SQLite (conversations, memory, config)
â”œâ”€â”€ Embedded BadgerDB (sessions, queue, vectors)
â”œâ”€â”€ HTTP API + WebSocket Server (Go/Fiber)
â”œâ”€â”€ Agent Runtime (goroutines for concurrency)
â”œâ”€â”€ Tool System (file, shell, web, etc.)
â”œâ”€â”€ Skills Registry (GitHub, Weather, Notes)
â”œâ”€â”€ Telegram Bot (multi-channel support)
â””â”€â”€ Static Web UI (embedded)
```

## ğŸ“Š Performance vs Alternatives

| Metric | Clawdbot | Python Nanobot | **Jimmy.ai** |
|--------|----------|----------------|--------------|
| Binary Size | ~2GB | ~500MB | **~50MB** |
| Memory (idle) | 2GB | 500MB | **25MB** |
| Startup Time | Minutes | 10s | **50ms** |
| Concurrent Chats | 10 | 20 | **100+** |
| Deploy Command | `kubectl` | `docker-compose` | **`./jimmy`** |

## ğŸ—ºï¸ Roadmap

- âœ… **v0.3** - Skills system, Telegram bot, tool streaming
- ğŸ”„ **v0.4** - Cron scheduler, Discord/Slack, more skills
- ğŸ”„ **v0.5** - Vector memory (RAG), MCP protocol, web browsing
- ğŸ”„ **v1.0** - Multi-LLM support, skill marketplace, mobile apps

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- Inspired by [OpenClaw](https://github.com/openclaw/openclaw)
- Original [nanobot](https://github.com/HKUDS/nanobot) by HKUDS
- Built with Go, SQLite, and â¤ï¸

---

**Star â­ this repo if you find it useful!**
